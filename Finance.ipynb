{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach Tried\n",
    "\n",
    "* Normalization\n",
    "* Feature transformation using boxcox for skewed features\n",
    "* SMOTE for over sampling\n",
    "* Balancing Ensemble technique\n",
    "* Stacked Classifier\n",
    "* New feature addition using existing ones\n",
    "* Missing values imputation using Most Frequent method specific to each class.\n",
    "* Various Ensemble models with or without using Balancing technique\n",
    "* Various different encoding techniqueâ€™s combination like target encoding , helmert, sum encoder, frequency encoding, OHE etc\n",
    "\n",
    "Most of the above techniques did not work out so I moved out the code related to them to commented section as much as I was able to recollect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/finalsub/test-data.csv\n",
      "/kaggle/input/finalsub/train.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import preprocessing \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):    \n",
    "    #Missing Values imputation using most Frequent method \n",
    "    #for those columns who are having missing values less than 75%\n",
    "    \n",
    "    miss_feat=['Health Indicator','Holding_Policy_Duration','Holding_Policy_Type'] \n",
    "    for i in miss_feat:\n",
    "        df[i]=df[i].fillna(df[i].mode().iat[0])\n",
    "        \n",
    "    #Categorical features which are needed to be converted\n",
    "    cat_feat=['Accomodation_Type','Reco_Policy_Cat','Region_Code' ,'City_Code', 'Reco_Insurance_Type', 'Is_Spouse', 'Health Indicator', 'Holding_Policy_Duration']\n",
    "    #Converting using label_encoder \n",
    "    label_encoder = preprocessing.LabelEncoder() \n",
    "    for i in cat_feat:\n",
    "        df[i] = label_encoder.fit_transform(df[i])\n",
    "    #Converting using One hot encoding\n",
    "    df = pd.get_dummies(df, columns=['Holding_Policy_Type'])\n",
    "    #Normalize\n",
    "    mx=df['Reco_Policy_Premium'].max()\n",
    "    mn=df['Reco_Policy_Premium'].min()\n",
    "    for i in range(len(df['Reco_Policy_Premium'])):\n",
    "        df['Reco_Policy_Premium'][i]=(df['Reco_Policy_Premium'][i]-mn)/(mx-mn)\n",
    "    return df\n",
    "    \n",
    "#OUTLIER DETECTION\n",
    "def out_std(s, nstd=3):\n",
    "    data_mean, data_std = s.mean(), s.std()\n",
    "    cut_off = data_std * nstd\n",
    "    lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "    #print(lower, upper)\n",
    "    masked = [True if x < lower or x > upper else False for x in s]\n",
    "    if masked.count(True)!=0:\n",
    "        idx=[]\n",
    "        for i in range(len(masked)):\n",
    "            if masked[i]==True:\n",
    "                idx.append(i)\n",
    "        return idx\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/kaggle/input/finance/train.csv')\n",
    "X_test=pd.read_csv('/kaggle/input/finance/test-data.csv')\n",
    "\n",
    "df=df.drop(['ID','Lower_Age'],axis=1)\n",
    "ID=X_test['ID']\n",
    "X_test=X_test.drop(['ID','Lower_Age'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City_Code                   0.000000\n",
       "Region_Code                 0.000000\n",
       "Accomodation_Type           0.000000\n",
       "Reco_Insurance_Type         0.000000\n",
       "Upper_Age                   0.000000\n",
       "Lower_Age                   0.000000\n",
       "Is_Spouse                   0.000000\n",
       "Health Indicator           22.976691\n",
       "Holding_Policy_Duration    39.799929\n",
       "Holding_Policy_Type        39.799929\n",
       "Reco_Policy_Cat             0.000000\n",
       "Reco_Policy_Premium         0.000000\n",
       "Response                    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding missing Values % \n",
    "df.isnull().sum()*100/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Region's total no. of positive response  \n",
    "regn_resp_count=list(df.groupby('Region_Code').sum()['Response'])\n",
    "regns_idx=df.groupby('Region_Code').sum()['Response'].index\n",
    "\n",
    "regn_resp=pd.DataFrame({'Region_Code':regns_idx,'regn_resp_count':regn_resp_count})\n",
    "regn_resp=regn_resp.sort_values('Region_Code')\n",
    "\n",
    "#Region's total no. of counts and % of positive response \n",
    "regn_count=df.groupby('Region_Code').size()\n",
    "idx=regn_count.index\n",
    "regn_count=pd.DataFrame({'Region_Code':idx,'regn_counts':list(regn_count)})\n",
    "regn_count=regn_count.sort_values('Region_Code')\n",
    "regn_count['regn_resp_count']=regn_resp['regn_resp_count']\n",
    "regn_count['pct_response_r']=regn_count['regn_resp_count']/regn_count['regn_counts']\n",
    "\n",
    "df=df.merge(regn_count[['Region_Code','pct_response_r']],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Existing customer based on Holding_Policy_Type and Holding_Policy_Duration\n",
    "idx_exist_cust=df[df['Holding_Policy_Type'].isnull() & df['Holding_Policy_Duration'].isnull() ].index.tolist()\n",
    "df['Existing_Cust']=0\n",
    "for index, row in df.iterrows():\n",
    "    if int(index) in idx_exist_cust:\n",
    "        df['Existing_Cust'][index]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "X_test=preprocess(X_test)\n",
    "df=preprocess(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing Dataset\n",
    "Dividing Data set into 4 batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0=df[df['Response']==0].reset_index(drop=True)\n",
    "df1=df[df['Response']==1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "df01=df0[:12209]\n",
    "df02=df0[12209:24418]\n",
    "df03=df0[24418:36627]\n",
    "df04=df0[36627:38673]\n",
    "df14=df1.sample(2046)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11=pd.concat([df01,df1])\n",
    "df12=pd.concat([df02,df1])\n",
    "df13=pd.concat([df03,df1])\n",
    "df14=pd.concat([df04,df1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11=df11.sample(frac=1)\n",
    "df12=df12.sample(frac=1)\n",
    "df13=df13.sample(frac=1)\n",
    "df14=df14.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=df11['Response']\n",
    "X1=df11.drop(['Response'],axis=1)\n",
    "y2=df12['Response']\n",
    "X2=df12.drop(['Response'],axis=1)\n",
    "y3=df13['Response']\n",
    "X3=df13.drop(['Response'],axis=1)\n",
    "y4=df14['Response']\n",
    "X4=df14.drop(['Response'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:40:14] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:40:17] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:40:20] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:40:22] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "#Predicting on all 4.\n",
    "\n",
    "xg1=XGBClassifier(n_estimators=200)\n",
    "xg1.fit(X1,y1)\n",
    "y_pred1=xg1.predict_proba(X_test)[:, 1]\n",
    "\n",
    "xg2=XGBClassifier(n_estimators=200)    \n",
    "xg2.fit(X2,y2)                         \n",
    "y_pred2=xg2.predict_proba(X_test)[:, 1]\n",
    "\n",
    "xg3=XGBClassifier(n_estimators=200)    \n",
    "xg3.fit(X3,y3)                         \n",
    "y_pred3=xg3.predict_proba(X_test)[:, 1]\n",
    "   \n",
    "xg4=XGBClassifier(n_estimators=200)    \n",
    "xg4.fit(X4,y4)                         \n",
    "y_pred4=xg4.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced model for ensemble having 10% class 0 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:40:24] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "dfus0=df0.sample(1220)\n",
    "dfus1=df1\n",
    "dfus=pd.concat([dfus0,dfus1])\n",
    "\n",
    "yus=dfus['Response']\n",
    "Xus=dfus.drop(['Response'],axis=1)\n",
    "\n",
    "xgus=XGBClassifier(n_estimators=200)\n",
    "xgus.fit(Xus,yus)\n",
    "y_predus=xgus.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final probablities from each model\n",
    "y_final=[]\n",
    "for i in range(len(y_pred2)):\n",
    "    count=0\n",
    "    count=y_pred1[i]+y_pred2[i]+y_pred3[i]+y_pred4[i]+y_predus[i]\n",
    "    y_final.append(count/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing CSV file for predictions on Xtest\n",
    "test_pred=pd.DataFrame({'ID':ID,'Response':y_final})\n",
    "test_pred.to_csv('v15.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18431, 2)"
      ]
     },
     "execution_count": 674,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_pred[test_pred['Response']>0.5].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commented unused code\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Citys's total no. of positive response  \n",
    "# city_resp_count=list(df.groupby('City_Code').sum()['Response'])\n",
    "# cities_idx=df.groupby('City_Code').sum()['Response'].index\n",
    "\n",
    "# city_resp=pd.DataFrame({'City_Code':cities_idx,'city_resp_count':city_resp_count})\n",
    "# city_resp=city_resp.sort_values('City_Code')\n",
    "\n",
    "# #Citys's total no. of counts and % of positive response \n",
    "# city_count=df.groupby('City_Code').size()\n",
    "# idx=city_count.index\n",
    "# city_count=pd.DataFrame({'City_Code':idx,'city_counts':list(city_count)})\n",
    "# city_count=city_count.sort_values('City_Code')\n",
    "# city_count['city_resp_count']=city_resp['city_resp_count']\n",
    "# city_count['pct_response']=city_count['city_resp_count']/city_count['city_counts']\n",
    "# df=df.merge(city_count[['City_Code','pct_response']],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEABORN for finding out distribution of data\n",
    "\n",
    "# fig, axs = plt.subplots(ncols=2)\n",
    "# fig.tight_layout()\n",
    "# sns.histplot(data=df0.dropna(), x=\"pct_response\",ax=axs[0])\n",
    "# sns.histplot(data=df1.dropna(), x=\"pct_response\",ax=axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE for over sampling  \n",
    "# sm = SMOTE(random_state=2)\n",
    "# X_train_res, y_train_res = sm.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Outlier removal\n",
    "\n",
    "# s=set()\n",
    "# for i in df.columns:\n",
    "#     idx=out_std(df[i])\n",
    "#     if idx!=-1:\n",
    "#         #print(i,idx)\n",
    "#         s=s|set(idx)\n",
    "# df=df.drop(list(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency Encoder\n",
    "#         fq = df.groupby(i).size()/len(df)    \n",
    "#         # mapping values to dataframe \n",
    "#         df.loc[:, \"{}_freq_encode\".format(i)] = df[i].map(fq)   \n",
    "#         # drop original column. \n",
    "#         df = df.drop([i], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values imputation using Most Frequent method specific to each class.\n",
    "# df0=df[df['Response']==0]\n",
    "# df1=df[df['Response']==1]\n",
    "# miss_feat=['Health Indicator','Holding_Policy_Duration','Holding_Policy_Type'] \n",
    "# for i in miss_feat:\n",
    "#     df0[i]=df0[i].fillna(df0[i].mode().iat[0])\n",
    "#     df1[i]=df1[i].fillna(df1[i].mode().iat[0])\n",
    "# df=pd.concat([df0,df1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author**: Abhishek Soni\n",
    "\n",
    "**Email**: abhisheksoni@hotmail.com\n",
    "\n",
    "**Contact number**: +919772169889"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
